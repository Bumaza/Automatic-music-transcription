{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pmt_dnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkUNflinO6MrXrSTPHe0xW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bumaza/Automatic-music-transcription/blob/master/pmt_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIQnt20NnF86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoOREwgNnTkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/AMT/'\n",
        "DPATH = '/content/drive/My Drive/AMT/data352/'\n",
        "!ls \"/content/drive/My Drive/AMT/\"\n",
        "!pip install pretty_midi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMsfGKWWnVJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_MIDI_TONE = 21\n",
        "MAX_MIDI_TONE = 108\n",
        "NOTE_RANGE = MAX_MIDI_TONE - MIN_MIDI_TONE + 1\n",
        "ALL_MIDI_TONES = 128\n",
        "\n",
        "BIN_MULTIPLE = 4 # 3\n",
        "BIN_PER_OCTAVE = 12 * BIN_MULTIPLE\n",
        "N_BINS = NOTE_RANGE * BIN_MULTIPLE \n",
        "\n",
        "HYBRID_DIR = PATH + 'MAPS-orig/StbgTGd2/MUS/'\n",
        "BOESENDORFER_IMPERIAL_DIR = PATH + 'MAPS-orig/AkPnBsdf/MUS/'\n",
        "BECHSTEIN_DIR = PATH + 'MAPS-orig/AkPnBcht/MUS/'\n",
        "CONCERT_GRAND_DIR = PATH + 'MAPS-orig/AkPnCGdD/MUS/'\n",
        "STEINGRAEBER_DIR = PATH + 'MAPS-orig/AkPnStgb/MUS/'\n",
        "STEINWAY_DIR =  PATH + 'MAPS-orig/SptkBGAm/MUS/'\n",
        "STEINWAY_DIR2 =  PATH + 'MAPS-orig/SptkBGCl/MUS/'\n",
        "REAL_PIANO_DIR = PATH + 'MAPS-orig/ENSTDkCl/MUS/'\n",
        "\n",
        "# MAPS configuration\n",
        "train_set = set(['AkPnBcht', 'AkPnCGdD', 'AkPnStgb', 'SptkBGAm'])\n",
        "val_set = set(['SptkBGCl'])\n",
        "test_set = set(['ENSTDkCl']) \n",
        "\n",
        "print(STEINGRAEBER_DIR)\n",
        "\n",
        "MIDI_DIR = PATH + 'midi/' # CMPT datasets file\n",
        "MP3_DIR = PATH + 'mp3/'  # CMPT datasets file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMY9lPpjnjYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sklearn\n",
        "import pretty_midi\n",
        "from numpy import newaxis\n",
        "import seaborn as sns\n",
        "from matplotlib import colors \n",
        "\n",
        "\n",
        "\n",
        "MIN_LEVEL_DB = -100.0\n",
        "REF_LEVEL_DB = 20.0\n",
        "SAMPLE_RATE = 16000\n",
        "HOP_LENGTH = 512\n",
        "WIN_LENGTH = 1024\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "units = 125\n",
        "layers = 3\n",
        "dropout = 0.3\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# 1. DNN, 2. LSTM, 3. ConvNet, 4. ConvNet BNR\n",
        "MODEL_TYPE = 5\n",
        "FEATURES = 'cqt'\n",
        "\n",
        "\n",
        "PLOT = True\n",
        "\n",
        "\n",
        "def amp_to_db(x):\n",
        "    return 20.0 * np.log10(np.maximum(1e-5, x))\n",
        "\n",
        "\n",
        "def db_to_amp(x):\n",
        "    return np.power(10.0, x * 0.05)\n",
        "\n",
        "\n",
        "def normalize(S):\n",
        "    return np.clip(S / -MIN_LEVEL_DB, -1.0, 0.0) + 1.0\n",
        "\n",
        "\n",
        "def denormalize(S):\n",
        "    return (np.clip(S, 0.0, 1.0) - 1.0) * -MIN_LEVEL_DB\n",
        "\n",
        "\n",
        "def stft(y):\n",
        "    \"\"\" Compute STFT for audio\n",
        "     :param y:\n",
        "     :return:\n",
        "     \"\"\"\n",
        "    return librosa.stft(y=y, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)\n",
        "\n",
        "\n",
        "def istft(mag, phase):\n",
        "    \"\"\" Compute inverse STFT\n",
        "    :param mag:\n",
        "    :param phase:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    stft_matrix = mag * np.exp(1j * phase)\n",
        "    return librosa.istft(stft_matrix, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)\n",
        "\n",
        "def wav2spec(y):\n",
        "    \"\"\" Transform wav file amplitude to\n",
        "    time-frequency domain using stft algorithm\n",
        "    :param y:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    D = stft(y)\n",
        "    S = amp_to_db(np.abs(D)) - REF_LEVEL_DB\n",
        "    S, D = normalize(S), np.angle(D)\n",
        "    S, D = S.T, D.T  # to make [time, freq]\n",
        "    return S, D\n",
        "\n",
        "\n",
        "def spec2wav(spectrogram, phase):\n",
        "    \"\"\"\n",
        "    :param spectrogram:\n",
        "    :param phase:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    spectrogram, phase = spectrogram.T, phase.T\n",
        "    # used during inference only\n",
        "    # spectrogram: enhanced output\n",
        "    # phase: use noisy input's phase, so no GLA is required\n",
        "    S = db_to_amp(denormalize(spectrogram) + REF_LEVEL_DB)\n",
        "    return istft(S, phase) \n",
        "\n",
        "\n",
        "def wav2cqt_spec(wav_file, windowed = False):\n",
        "    \"\"\" Convert wav file to cqT spectogram\n",
        "    :param wav_file:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    y, sr = librosa.load(os.path.join(MP3_DIR, wav_file), sr=SAMPLE_RATE)\n",
        "    # Transpose so that the data is in [frame, bins] format.\n",
        "    C = librosa.cqt(y, sr=SAMPLE_RATE, fmin=librosa.midi_to_hz(MIN_MIDI_TONE),\n",
        "                    hop_length=HOP_LENGTH, bins_per_octave=BIN_PER_OCTAVE, n_bins=N_BINS).T\n",
        "    C = np.absolute(C)\n",
        "\n",
        "    if PLOT:\n",
        "      librosa.display.specshow(librosa.amplitude_to_db(C.T, ref=np.max), y_axis='cqt_note', x_axis='time', sr=SAMPLE_RATE, hop_length=HOP_LENGTH, bins_per_octave=BIN_PER_OCTAVE)\n",
        "      plt.title('constant-Q transform of ' + track)\n",
        "      plt.colorbar(format='%+2.0f dB')\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "    #C = librosa.amplitude_to_db(C, ref=np.max)\n",
        "    #C = sklearn.preprocessing.normalize(C)\n",
        "    #minDB = np.min(C)\n",
        "\n",
        "    if windowed:\n",
        "        windows = [C[i:i + WINDOW_SIZE, :] for i in range(C.shape[0] - WINDOW_SIZE + 1)]\n",
        "        return np.array(windows)\n",
        "\n",
        "    return C\n",
        "\n",
        "  \n",
        "def wav2mel(wav_file):\n",
        "  \"\"\"Transforms the contents of a wav file into a series of mel spec frames.\"\"\"\n",
        "  y, _ = librosa.load(os.path.join(MP3_DIR, wav_file), sr=SAMPLE_RATE)\n",
        "\n",
        "  mel = librosa.feature.melspectrogram(y, SAMPLE_RATE, hop_length=HOP_LENGTH, fmin=librosa.midi_to_hz(MIN_MIDI_TONE), n_mels=229)\n",
        "\n",
        "  if PLOT:\n",
        "      librosa.display.specshow(librosa.amplitude_to_db(mel, ref=np.max), y_axis='cqt_note', x_axis='time', sr=SAMPLE_RATE, hop_length=HOP_LENGTH, bins_per_octave=BIN_PER_OCTAVE)\n",
        "      plt.title('Mel spectrum of ' + track)\n",
        "      plt.colorbar(format='%+2.0f dB')\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  # Transpose so that the data is in [frame, bins] format.\n",
        "  mel = mel.T\n",
        "  return mel \n",
        "\n",
        "\n",
        "def midi2labels(midi_file, times):\n",
        "    \"\"\" Convert midi file to a piano roll\n",
        "    :param midi_file:\n",
        "    :param times:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    pm = pretty_midi.PrettyMIDI(os.path.join(MIDI_DIR, midi_file))\n",
        "    piano_roll = pm.get_piano_roll(fs=100, times=times)[MIN_MIDI_TONE:MAX_MIDI_TONE + 1].T\n",
        "    piano_roll[piano_roll > 0] = 1\n",
        "    \n",
        "    if PLOT:\n",
        "      plot_predict(piano_roll)\n",
        "\n",
        "    return piano_roll\n",
        "\n",
        "\n",
        "def plot_predict(y, truth=False):\n",
        "    cmap = colors.ListedColormap(['white', 'black'])\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 5))\n",
        "    plt.title('Ground Truth' if truth else 'Predict')\n",
        "    plt.imshow(y.T, aspect='auto', cmap=cmap) #, \n",
        "    plt.gca().invert_yaxis()\n",
        "    fig.axes[0].set_xlabel('window')\n",
        "    fig.axes[0].set_ylabel('note (MIDI code')\n",
        "    plt.show()    \n",
        "    \n",
        "def postprocess(y_pred):\n",
        "\n",
        "    # if not self.preprocessing:\n",
        "    #     return y_pred\n",
        "\n",
        "    y_pred = np.array(y_pred).round()\n",
        "    y_pred[y_pred > 1] = 1\n",
        "\n",
        "\n",
        "    changes = 0\n",
        "\n",
        "    for note in range(y_pred.shape[1]):\n",
        "        for frame in range(2, y_pred.shape[0] - 3):\n",
        "\n",
        "            if list(y_pred[frame-1:frame+3, note]) == [1.0, 0.0, 0.0, 1.0]:\n",
        "                y_pred[frame, note], y_pred[frame + 1, note] = 1, 1\n",
        "                changes += 1\n",
        "\n",
        "            if list(y_pred[frame-2:frame+4, note]) == [0.0, 0.0, 1.0, 1.0, 0.0, 0.0]:\n",
        "                y_pred[frame, note], y_pred[frame + 1, note] = 0, 0\n",
        "                changes += 1\n",
        "\n",
        "            if list(y_pred[frame-1:frame+3, note]) == [0.0, 1.0, 0.0, 0.0]:\n",
        "                y_pred[frame, note] = 0\n",
        "                changes += 1\n",
        "\n",
        "            if list(y_pred[frame-1:frame+3, note]) == [1.0, 0.0, 1.0, 1.0]:\n",
        "                y_pred[frame, note] = 1\n",
        "                changes += 1\n",
        "\n",
        "    print('Total changes: {0}'.format(changes))\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1lKnxIGoAVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code for preprocessing CMPT dataset\n",
        "\n",
        "from os import listdir\n",
        "\n",
        "np.random.seed()\n",
        "\n",
        "tracks = [x for x in listdir(MP3_DIR) if x.endswith('.wav')]\n",
        "np.random.shuffle(tracks)\n",
        "\n",
        "print(len(tracks), tracks[0])\n",
        "\n",
        "i, length = 1, len(tracks)\n",
        "\n",
        "X_all, y_all = None, None\n",
        "\n",
        "pretty_midi.pretty_midi.MAX_TICK = 1e10\n",
        "\n",
        "for track in tracks: \n",
        "    try:\n",
        "        X = wav2cqt_spec(track)\n",
        "        times = librosa.frames_to_time(np.arange(X.shape[0]), sr=SAMPLE_RATE, hop_length=HOP_LENGTH)\n",
        "        y = midi2labels('{0}.mid'.format(track.split('.')[0]), times)\n",
        "\n",
        "        if X_all is None or y_all is None:\n",
        "            X_all, y_all = X, y\n",
        "        elif X.shape[0] == y.shape[0]:\n",
        "            X_all, y_all = np.concatenate((X_all, X)), np.concatenate((y_all, y))\n",
        "\n",
        "        print('{0}/{1} {2} {3}.mid'.format(i, length, track, track.split('.')[0]), X.shape, '/', X_all.shape, y.shape, '/', y_all.shape)\n",
        "        i += 1\n",
        "\n",
        "    except FileNotFoundError as err:\n",
        "        print(err)\n",
        "    except Exception as err:\n",
        "        print(err)\n",
        "\n",
        "print(X_all.shape, y_all.shape)\n",
        "\n",
        "np.save(PATH + MIDI_DIR.split('/')[-3] + '_input.npy', X_all)\n",
        "np.save(PATH + MIDI_DIR.split('/')[-3] + '_output.npy', y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KenmOaAnoJBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading CPMT dataset\n",
        "\n",
        "\n",
        "X_train, y_train = np.load(DPATH+'train_input_cqt.npy')[:827025], np.load(PATH+'train_output_cqt.npy')[:827025]\n",
        "X_validate, y_validate = np.load(DPATH+'val_input_cqt.npy')[:242604], np.load(PATH+'val_output_cqt.npy')[:242604]\n",
        "\n",
        "min_train, max_train = X_train.min(axis=0), X_train.max(axis=0)\n",
        "min_val, max_val = X_validate.min(axis=0), X_validate.max(axis=0)\n",
        "\n",
        "X_train = (X_train - min_train) / (max_train - min_train)\n",
        "X_validate = (X_validate - min_val) / (max_val - min_val)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_validate.shape, y_validate.shape) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9PBaPs8rE7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading MIMAS piano part \n",
        "X_train, y_train = np.load(DPATH+'folk_piano_train_input.npy'), np.load(DPATH+'folk_piano_train_output.npy')\n",
        "X_validate, y_validate = np.load(DPATH+'folk_piano_val_input.npy'), np.load(DPATH+'folk_piano_val_output.npy')\n",
        "\n",
        "min_train, max_train = X_train.min(axis=0), X_train.max(axis=0)\n",
        "min_val, max_val = X_validate.min(axis=0), X_validate.max(axis=0)\n",
        "\n",
        "X_train = (X_train - min_train) / (max_train - min_train)\n",
        "X_validate = (X_validate - min_val) / (max_val - min_val)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_validate.shape, y_validate.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAN9YEtLoNip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading MAPS dataset TRAIN \n",
        "X_train, y_trian = None, None\n",
        "\n",
        "for data in train_set:\n",
        "  if X_train is None:\n",
        "    X_train, y_train = np.load(DPATH+data+'_input.npy'), np.load(DPATH+data+'_output.npy')\n",
        "  else:\n",
        "    X_train, y_train = np.concatenate((X_train, np.load(DPATH+data+'_input.npy'))), np.concatenate((y_train, np.load(DPATH+data+'_output.npy')))\n",
        "\n",
        "min_train, max_train = X_train.min(axis=0), X_train.max(axis=0)\n",
        "X_train = (X_train - min_train) / (max_train - min_train)\n",
        "\n",
        "print('TRAIN DATA: ', X_train.shape, y_train.shape)\n",
        "\n",
        "X_validate, y_validate = None, None\n",
        "\n",
        "for data in val_set:\n",
        "  if X_validate is None:\n",
        "    X_validate, y_validate = np.load(DPATH+data+'_input.npy'), np.load(DPATH+data+'_output.npy')\n",
        "  else:\n",
        "    X_validate, y_validate = np.concatenate((X_validate, np.load(DPATH+data+'_input.npy'))), np.concatenate((y_validate, np.load(DPATH+data+'_output.npy')))\n",
        "\n",
        "min_val, max_val = X_validate.min(axis=0), X_validate.max(axis=0)\n",
        "X_validate = (X_validate - min_val) / (max_val - min_val)\n",
        "\n",
        "print('VALIDATION DATA: ', X_validate.shape, y_validate.shape)\n",
        "\n",
        "#MAPS dataset TEST\n",
        "X_test, y_test = None, None\n",
        "\n",
        "for data in test_set:\n",
        "  if X_test is None:\n",
        "    X_test, y_test = np.load(DPATH+data+'_input.npy'), np.load(DPATH+data+'_output.npy')\n",
        "  else:\n",
        "    X_test, y_test = np.concatenate((X_test, np.load(DPATH+data+'_input.npy'))), np.concatenate((y_test, np.load(DPATH+data+'_output.npy')))\n",
        "\n",
        "min_test, max_test = X_test.min(axis=0), X_test.max(axis=0)\n",
        "X_test = (X_test - min_test) / (max_test - min_test)\n",
        "\n",
        "print('TEST DATA: ', X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpEkyZkGoRxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility callback for ploting posteigroms during training process \n",
        "\n",
        "import sklearn\n",
        "from keras import backend as K\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "class CheckMidi(Callback):\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.X = None\n",
        "\n",
        "    PRED_SIZE = 10000\n",
        "\n",
        "    for data in test_set:\n",
        "      self.X = np.load(PATH+data+'_input.npy')\n",
        "\n",
        "    min_test, max_test = self.X.min(axis=0), self.X.max(axis=0)\n",
        "    self.X = (self.X - min_test) / (max_test - min_test)\n",
        "\n",
        "    if MODEL_TYPE > 2:\n",
        "      self.X = np.array([self.X[i:i+WINDOW_SIZE, :] for i in range(0, PRED_SIZE - WINDOW_SIZE + 1)])[..., newaxis]\n",
        "    elif MODEL_TYPE == 2: #INPUT FOR LSTM\n",
        "      self.X = np.array([self.X[i:i+BATCH_SIZE, :] for i in range(0, PRED_SIZE - BATCH_SIZE + 1, BATCH_SIZE)])\n",
        "\n",
        "    print('Check MIDI: ',  self.X.shape)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    y_pred = self.model.predict(self.X, batch_size=BATCH_SIZE, verbose=1)\n",
        "    if MODEL_TYPE == 2: #LSTM\n",
        "      y = None\n",
        "      for i in range(0, len(y_pred)):\n",
        "          if y is None:\n",
        "            y = y_pred[i]\n",
        "          else:\n",
        "            y = np.concatenate((y, y_pred[i]))\n",
        "      print(y.shape)\n",
        "      y_pred = y\n",
        "\n",
        "    plot_predict(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evwD81snok5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data generator for efficiently manipulation with RAM memory\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.step = 0\n",
        "    self.data = data\n",
        "    self.current_file = 0\n",
        "    self.audio, self.midi = None, None\n",
        "\n",
        "    self.count_steps()\n",
        "    self.load_normalize_slice()\n",
        "\n",
        "\n",
        "  def count_steps(self):\n",
        "    for d in self.data:\n",
        "      m = np.load(PATH+d+'_output.npy')\n",
        "      s = len(m) + 1 - WINDOW_SIZE\n",
        "      self.step += s // BATCH_SIZE\n",
        "\n",
        "\n",
        "  def load_normalize_slice(self):\n",
        "    self.audio, self.midi = np.load(PATH+self.data[self.current_file]+'_input.npy'), np.load(PATH+self.data[self.current_file]+'_output.npy')\n",
        "    ''' normalize data '''\n",
        "    min_train, max_train = self.audio.min(axis=0), self.audio.max(axis=0)\n",
        "    self.audio = (self.audio - min_train) / (max_train - min_train)\n",
        "\n",
        "    ''' slice to windows '''\n",
        "    SIZE = len(self.audio)\n",
        "    self.audio = np.array([self.audio[j:j+WINDOW_SIZE, :] for j in range(0, SIZE - WINDOW_SIZE + 1)])[..., newaxis]\n",
        "    self.midi = self.midi[:SIZE + 1 - WINDOW_SIZE,:]\n",
        "\n",
        "    print('DataGenerator: ', self.audio.shape, self.midi.shape)\n",
        "\n",
        "\n",
        "  def steps(self):\n",
        "    return self.step\n",
        "\n",
        "  def next(self):\n",
        "    i = 0\n",
        "    while True:\n",
        "      \n",
        "      if (i+1) * BATCH_SIZE > self.audio.shape[0]:\n",
        "        \n",
        "        X, y = self.audio[i * BATCH_SIZE:], self.midi[i * BATCH_SIZE:]\n",
        "        i = 0\n",
        "\n",
        "        if len(self.data) > 1:\n",
        "          self.current_file = (self.current_file + 1) % len(self.data)\n",
        "          self.load_normalize_slice()\n",
        "\n",
        "      else:\n",
        "        X, y = self.audio[i * BATCH_SIZE:(i+1)* BATCH_SIZE], self.midi[i * BATCH_SIZE: (i+1) * BATCH_SIZE]\n",
        "        i += 1\n",
        "\n",
        "      yield X, y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUJIOvOaorX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from keras import backend as K\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class LinearDecay(Callback):\n",
        "   \n",
        "    def __init__(self, initial_lr, epochs):\n",
        "        super(LinearDecay, self).__init__()\n",
        "        self.initial_lr = initial_lr\n",
        "        self.decay = initial_lr/epochs\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        new_lr = self.initial_lr - self.decay*epoch\n",
        "        print(\"ld: learning rate is now \"+str(new_lr))\n",
        "        K.set_value(self.model.optimizer.lr, new_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stbUoUrbovNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DNN & LSTM models implementation\n",
        "from keras.optimizers import Adam, Adadelta, SGD\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Dense, Flatten, Reshape, Input, LSTM, add\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "MODEL_PATH = PATH + 'Sigtia/models/'\n",
        "\n",
        "dataset = 'maps' # 'cmpt', 'mimas'\n",
        "optimizer = 'adam' #sgd\n",
        "\n",
        "model = Sequential()\n",
        "model_file = MODEL_PATH + 'dnn_{0}_{1}.hdf5'.format(layers, optimizer)\n",
        "\n",
        "MODEL_TYPE = 5\n",
        "units = 125\n",
        "layers = 3\n",
        "\n",
        "\n",
        "\n",
        "if MODEL_TYPE == 1: #229\n",
        "  model.add(Dense(units, input_shape=(N_BINS, ), kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  for _ in range(layers - 1):\n",
        "    model.add(Dense(units, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(NOTE_RANGE, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "elif MODEL_TYPE == 2: # RNN\n",
        "  # input 3d array(batch_size, time_steps, seq_len)\n",
        "  model_file = MODEL_PATH + 'lstm_{0}_{1}.hdf5'.format(layers, optimizer)\n",
        "  model.add(LSTM(units, input_shape=(BATCH_SIZE, N_BINS), return_sequences=True, kernel_initializer='normal', activation='tanh'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  for _ in range(1):\n",
        "    model.add(LSTM(units, return_sequences=True, kernel_initializer='normal', activation='tanh'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "  # return_sequence -> TRUE  - output 3d array (batch_size, time_steps, units)\n",
        "  # return_sequence -> FALSE - output 2d array (batch_size, units)\n",
        "  model.add(Dense(NOTE_RANGE, kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "elif MODEL_TYPE == 3:\n",
        "  model_file = MODEL_PATH + 'convnet_{0}_{1}.hdf5'.format(dataset, optimizer)\n",
        "  # 1. CNN layer\n",
        "  model.add(Conv2D(50, (5, 25), input_shape=(WINDOW_SIZE, N_BINS, 1), activation='tanh'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(MaxPooling2D(pool_size=(1, 3)))\n",
        "\n",
        "  # 2. CNN layer\n",
        "  model.add(Conv2D(50, (3, 5), activation='tanh'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(MaxPooling2D(pool_size=(1, 3)))\n",
        "\n",
        "  # Flatten layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1000, activation='sigmoid'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Final layer\n",
        "  model.add(Dense(200, activation='sigmoid'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(NOTE_RANGE, activation='sigmoid'))\n",
        "\n",
        "elif MODEL_TYPE == 4:\n",
        "  model_file = MODEL_PATH + 'convnetBNR_{0}_{1}.hdf5'.format(dataset)\n",
        "  # 1. CNN layer\n",
        "  model.add(Conv2D(50, (5, 25), input_shape=(WINDOW_SIZE, N_BINS, 1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "\n",
        "  # 2. CNN layer\n",
        "  model.add(Conv2D(50, (3, 5)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "\n",
        "  # Flatten layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1000))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # Final layer\n",
        "  model.add(Dense(200))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(NOTE_RANGE, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "decay = LinearDecay(0.001, 1000)\n",
        "checkpoint = ModelCheckpoint(filepath=model_file, verbose=1, save_best_only=False)\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "checkMidi = CheckMidi(list(test_set))\n",
        "\n",
        "callbacks = [checkpoint, earlystop, decay, checkMidi]\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#plot_model(model, to_file=PATH + 'model_{0}.png'.format(MODEL_TYPE), show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKzzMQupnd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# windows for ConvNets\n",
        "from numpy import newaxis\n",
        "\n",
        "SIZE = len(X_train)\n",
        "\n",
        "X_train = np.array([X_train[i:i+WINDOW_SIZE, :] for i in range(0, SIZE - WINDOW_SIZE + 1)])[..., newaxis]\n",
        "y_train = y_train[:SIZE + 1 - WINDOW_SIZE,:]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "SIZE = len(X_validate)\n",
        "\n",
        "X_validate = np.array([X_validate[i:i+WINDOW_SIZE, :] for i in range(0, SIZE - WINDOW_SIZE + 1)])[..., newaxis]\n",
        "y_validate = y_validate[:SIZE + 1 - WINDOW_SIZE,:]\n",
        "\n",
        "print(X_validate.shape)\n",
        "print(y_validate.shape)\n",
        "\n",
        "SIZE = len(X_test)\n",
        "\n",
        "X_test = np.array([X_test[i:i+WINDOW_SIZE, :] for i in range(0, SIZE - WINDOW_SIZE + 1)])[..., newaxis]\n",
        "y_test = y_test[:SIZE + 1 - WINDOW_SIZE,:]\n",
        "\n",
        "print(X_validate.shape)\n",
        "print(y_validate.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzaitkSQpz8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM INPUT\n",
        "\n",
        "X_train = np.array([X_train[i:i+BATCH_SIZE, :] for i in range(0, len(X_train) - BATCH_SIZE + 1, BATCH_SIZE)])\n",
        "X_validate = np.array([X_validate[i:i+BATCH_SIZE, :] for i in range(0, len(X_validate) - BATCH_SIZE + 1, BATCH_SIZE)])\n",
        "\n",
        "y_train = np.array([y_train[i:i+BATCH_SIZE, :] for i in range(0, len(y_train) - BATCH_SIZE + 1, BATCH_SIZE)])\n",
        "y_validate = np.array([y_validate[i:i+BATCH_SIZE, :] for i in range(0, len(y_validate) - BATCH_SIZE + 1, BATCH_SIZE)])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_validate.shape, y_validate.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiu8DPurp156",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FIT generator\n",
        "\n",
        "trainGenerator = DataGenerator(list(train_set))\n",
        "valGenerator = DataGenerator(list(val_set))\n",
        "\n",
        "save = model.fit_generator(trainGenerator.next(), trainGenerator.steps(), epochs=1000, verbose=1, validation_data=valGenerator.next(), validation_steps=valGenerator.steps(), callbacks=callbacks)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxeX8P9Bp4CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1000\n",
        "\n",
        "save = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=10, validation_data=(X_validate, y_validate) ,verbose=1, callbacks=callbacks)\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "with open(HISTORY_PATH +'history{0}_{1}_{2}.json'.format(MODEL_TYPE, dataset, optimizer), 'w') as f:\n",
        "    json.dump(save.history, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmyEYBHFqFLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(y_pred, y_test):\n",
        "  a = min(len(y_pred), len(y_test))\n",
        "  y_test = y_test[:a]\n",
        "  y_pred = y_pred[:a]\n",
        "\n",
        "  #y_pred = np.array()\n",
        "\n",
        "  TP = np.count_nonzero(np.logical_and( y_pred == 1, y_test == 1 ))\n",
        "  FN = np.count_nonzero(np.logical_and( y_pred == 0, y_test == 1 ))\n",
        "  FP = np.count_nonzero(np.logical_and( y_pred == 1, y_test == 0 ))\n",
        "\n",
        "  A, F, R, P = 0, 0, 0, 0\n",
        "\n",
        "  if (TP + FN) > 0:\n",
        "    R, P = TP / float(TP + FN), TP / float(TP + FP)\n",
        "    A = 100 * TP / float(TP + FP + FN)\n",
        "    F = 100 * 2 * P * R / (P+R)\n",
        "    \n",
        "\n",
        "  print('Precision: ', P)\n",
        "  print('Recall: ', R)\n",
        "  print('F-measure: ', F)\n",
        "  print('Accuracy: ', A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqNvILDnqKsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Evaluation\n",
        "PRED_SIZE = len(X_test)\n",
        "\n",
        "MODEL_TYPE = 1\n",
        "\n",
        "print('TEST DATA: ', X_test.shape, y_test.shape)\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "# Sigtia/models/\n",
        "\n",
        "model = load_model(PATH +'My 352/models/cnn2_folk_adam.hdf5') #lstm_maps_3_cqt\n",
        "\n",
        "y_pred = model.predict(X_test[:PRED_SIZE], batch_size=256, verbose=1)\n",
        "\n",
        "if MODEL_TYPE == 2: #LSTM\n",
        "  y = None\n",
        "  for i in range(0, len(y_pred)):\n",
        "      if y is None:\n",
        "        y = y_pred[i]\n",
        "      else:\n",
        "        y = np.concatenate((y, y_pred[i]))\n",
        "  print(y.shape)\n",
        "  y_pred = y\n",
        "\n",
        "\n",
        "plot_predict(y_pred)\n",
        "y_pred = np.array(y_pred).round()\n",
        "\n",
        "metrics(y_pred, y_test)\n",
        "\n",
        "y_pred = postprocess(y_pred)\n",
        "\n",
        "metrics(y_pred, y_test)\n",
        "plot_predict(y_pred)\n",
        "\n",
        "plot_predict(y_test[:PRED_SIZE])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oekVXgTIq7D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}